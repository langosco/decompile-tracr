{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 15:30:15.208262: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "from pathlib import Path\n",
    "import time\n",
    "import sys\n",
    "from collections import defaultdict \n",
    "from typing import Union, TypeVar\n",
    "import h5py\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import jax\n",
    "import flax\n",
    "import chex\n",
    "from jaxtyping import ArrayLike\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import einops\n",
    "\n",
    "from tracr.compiler.validating import validate\n",
    "from tracr.rasp.rasp import Map, SequenceMap, LinearSequenceMap, Select, Aggregate, Comparison, SelectorWidth, indices, tokens \n",
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import compiling\n",
    "from tracr.compiler.assemble import AssembledTransformerModel\n",
    "from tracr.compiler.craft_model_to_transformer import NoTokensError\n",
    "from tracr.compiler.basis_inference import InvalidValueSetError\n",
    "from tracr.compiler import craft_graph_to_model\n",
    "from tracr.compiler import rasp_to_graph\n",
    "from tracr.compiler import lib as tracr_lib\n",
    "from tracr.compiler import assemble\n",
    "from tracr.transformer import model\n",
    "from tracr.transformer.model import CompiledTransformerModel\n",
    "from tracr.transformer.encoder import CategoricalEncoder\n",
    "from tracr.compiler.assemble import AssembledTransformerModel\n",
    "\n",
    "from decompile_tracr.dataset import lib\n",
    "from decompile_tracr.dataset import data_utils\n",
    "from decompile_tracr.dataset import dataloading\n",
    "from decompile_tracr.dataset import config\n",
    "from decompile_tracr.dataset import compile as comp\n",
    "from decompile_tracr.tokenizing import tokenizer\n",
    "from decompile_tracr.tokenizing import vocab\n",
    "from decompile_tracr.sampling import sampling\n",
    "from decompile_tracr.sampling import rasp_utils\n",
    "from decompile_tracr.sampling.map_primitives import FunctionWithRepr\n",
    "from decompile_tracr.training.autoencoder import get_residuals_sampler\n",
    "from decompile_tracr.training import autoencoder\n",
    "from decompile_tracr.training import transformer\n",
    "from decompile_tracr.training.transformer import Residuals\n",
    "\n",
    "from metamodels_for_rasp.train import Updater, TrainState\n",
    "\n",
    "\n",
    "def _compile(program):\n",
    "    return compiling.compile_rasp_to_model(\n",
    "        program,\n",
    "        vocab=set(range(5)),\n",
    "        max_seq_len=5,\n",
    "    )\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "key = jax.random.key(0)\n",
    "\n",
    "PLOT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "program_toks = tokenizer.tokenize(sampling.sample(\n",
    "    rng, program_length=5, only_categorical=True))\n",
    "assembled_model = comp.compile_tokens_to_model(program_toks)\n",
    "\n",
    "m = assembled_model\n",
    "\n",
    "def sample_tokens(key: jax.random.PRNGKey):\n",
    "    \"\"\"Utility function to sample \n",
    "    a random sequence of input tokens.\n",
    "    \"\"\"\n",
    "    batch_size = 1\n",
    "    seq_len = 6\n",
    "    bos: int = assembled_model.input_encoder.bos_encoding\n",
    "    inputs = jax.random.randint(key, (batch_size, seq_len-1), 0, 5)\n",
    "    inputs = jnp.concatenate(\n",
    "        [bos * jnp.ones((batch_size, 1), dtype=int), inputs], axis=1)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def _embed(tokens):\n",
    "    compiled_model = assembled_model.get_compiled_model()\n",
    "    return compiled_model.embed(tokens)\n",
    "\n",
    "\n",
    "def embed(tokens: jnp.ndarray):\n",
    "    return _embed.apply(assembled_model.params, tokens)\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def _unembed(x):\n",
    "    cm = assembled_model.get_compiled_model()\n",
    "    return cm.unembed(x, use_unembed_argmax=cm.use_unembed_argmax)\n",
    "\n",
    "def unembed(x):\n",
    "    return _unembed.apply(assembled_model.params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training autoencoder took 8.81s\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "key, subkey = jax.random.split(key)\n",
    "ae_state, ae_log, ae_model = autoencoder.train_autoencoder(\n",
    "    subkey, assembled_model, nsteps=10000)\n",
    "print(f'training autoencoder took {time.time() - t:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plt.plot([x['train/loss'] for x in ae_log])\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    print('final loss:', ae_log[-1]['train/loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# compare to original\n",
    "inputs = [0, 0, 4, 1, 2]\n",
    "x = np.array([assembled_model.input_encoder.bos_encoding] + inputs)\n",
    "x = np.expand_dims(x, 0)\n",
    "assembled_out = assembled_model.apply(['compiler_bos'] + inputs)\n",
    "\n",
    "original = np.concatenate(assembled_out.residuals)\n",
    "decoded = ae_model.apply({'params': ae_state.params}, original)\n",
    "decoded = np.array(decoded, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_range(*arrays):\n",
    "    all = np.concatenate(arrays)\n",
    "    return all.min(), all.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    _min, _max = get_range(original, decoded)\n",
    "\n",
    "    fig, axs = plt.subplots(len(original), 2, figsize=[10, 10])\n",
    "\n",
    "    axs[0, 0].set_title('Original')\n",
    "    for i, res in enumerate(original):\n",
    "        im = axs[i, 0].imshow(res, vmin=_min, vmax=_max)\n",
    "        axs[i, 0].set_ylabel(f'Layer {i}')\n",
    "\n",
    "    axs[0, 1].set_title('Decoded')\n",
    "    for i, res in enumerate(decoded):\n",
    "        im = axs[i, 1].imshow(res, vmin=_min, vmax=_max)\n",
    "\n",
    "    for x in axs.flatten():\n",
    "        x.set_xticks(np.arange(original.shape[-1], step=2))\n",
    "        x.set_xticklabels(np.arange(original.shape[-1], step=2))\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plt.imshow(original - decoded)\n",
    "    plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_layer(x: ArrayLike):\n",
    "    unembedded = np.squeeze(unembed(x))\n",
    "    unembedded = unembedded.tolist()\n",
    "    print(\"unembedded:\", unembedded)\n",
    "    tokens = assembled_model.output_encoder.decode(unembedded)\n",
    "    return ['compiler_bos'] + tokens[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['compiler_bos', 3, 3, 2, 2, 2]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembled_out.decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6, 37)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(decode_layer(original))\n",
    "# print(decode_layer(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_idx = 0\n",
    "# decoded_residuals = ae_model.apply(\n",
    "#     {'params': ae_state.params}, assembled_out.residuals[layer_idx])\n",
    "# \n",
    "# print(decode_layer(assembled_out.residuals[layer_idx]))\n",
    "# print(decode_layer(decoded_residuals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.squeeze(decoded_residuals).astype(np.float32)\n",
    "# y = np.squeeze(assembled_out.residuals[layer_idx])\n",
    "\n",
    "# fig, axs = plt.subplots(2, 1)\n",
    "# axs[0].imshow(x)\n",
    "# axs[1].imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per layer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    return ae_model.apply({'params': ae_state.params}, x, method=ae_model.encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch = transformer.DataGenerator(\n",
    "    assembled_model=assembled_model,\n",
    "    encode=encode,\n",
    "    batch_size=32,\n",
    "    seq_len=6,\n",
    ")\n",
    "\n",
    "model, state, log = transformer.train_transformer(\n",
    "    subkey, \n",
    "    get_batch=get_batch, \n",
    "    args=transformer.TransformerTrainingArgs(\n",
    "        nsteps=1000,\n",
    "        learning_rate=1e-3,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plt.plot([x['train/loss'] for x in log])\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    print('final loss:', log[-1]['train/loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = assembled_model\n",
    "\n",
    "def sample_tokens(key: jax.random.PRNGKey):\n",
    "    \"\"\"Utility function to sample \n",
    "    a random sequence of input tokens.\n",
    "    \"\"\"\n",
    "    batch_size = 1\n",
    "    seq_len = 6\n",
    "    bos: int = assembled_model.input_encoder.bos_encoding\n",
    "    inputs = jax.random.randint(key, (batch_size, seq_len-1), 0, 5)\n",
    "    inputs = jnp.concatenate(\n",
    "        [bos * jnp.ones((batch_size, 1), dtype=int), inputs], axis=1)\n",
    "    return inputs\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def _embed(tokens):\n",
    "    compiled_model = assembled_model.get_compiled_model()\n",
    "    return compiled_model.embed(tokens)\n",
    "\n",
    "\n",
    "def embed(tokens: jnp.ndarray):\n",
    "    return _embed.apply(assembled_model.params, tokens)\n",
    "\n",
    "\n",
    "@hk.without_apply_rng\n",
    "@hk.transform\n",
    "def _unembed(x):\n",
    "    cm = assembled_model.get_compiled_model()\n",
    "    return cm.unembed(x, use_unembed_argmax=cm.use_unembed_argmax)\n",
    "\n",
    "def unembed(x):\n",
    "    return _unembed.apply(assembled_model.params, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(x, y):\n",
    "    x, y = unembed(x), unembed(y)\n",
    "    return jnp.mean(x == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_residuals = get_residuals_sampler(\n",
    "    assembled_model,\n",
    "    seq_len=6,\n",
    "    batch_size=1,\n",
    "    flatten_leading_axes=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "res = get_residuals(subkey)\n",
    "decoded = ae_model.apply({'params': ae_state.params}, res.residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(m.output_encoder, CategoricalEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[2, 1, 2, 5, 2, 4],\n",
       "        [2, 1, 2, 5, 2, 4],\n",
       "        [2, 3, 3, 3, 3, 3],\n",
       "        [2, 3, 3, 3, 3, 3],\n",
       "        [2, 1, 2, 1, 2, 1],\n",
       "        [2, 1, 2, 1, 2, 1],\n",
       "        [2, 1, 2, 2, 2, 1],\n",
       "        [2, 1, 2, 2, 2, 1],\n",
       "        [2, 1, 2, 2, 2, 2]]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembed(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 2, 2, 2, 2]]], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembed(res.residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(0.0925926, dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(res.residuals, decoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
