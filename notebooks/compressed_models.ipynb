{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "from pathlib import Path\n",
    "import time\n",
    "import sys\n",
    "from collections import defaultdict \n",
    "from typing import Union, TypeVar\n",
    "import h5py\n",
    "import traceback\n",
    "\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import jax\n",
    "import flax\n",
    "import chex\n",
    "from jaxtyping import ArrayLike\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import einops\n",
    "\n",
    "from tracr.compiler.validating import validate\n",
    "from tracr.rasp.rasp import Map, SequenceMap, LinearSequenceMap, Select, Aggregate, Comparison, SelectorWidth, indices, tokens \n",
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import compiling\n",
    "from tracr.compiler.assemble import AssembledTransformerModel\n",
    "from tracr.compiler.craft_model_to_transformer import NoTokensError\n",
    "from tracr.compiler.basis_inference import InvalidValueSetError\n",
    "from tracr.compiler import craft_graph_to_model\n",
    "from tracr.compiler import rasp_to_graph\n",
    "from tracr.compiler import lib as tracr_lib\n",
    "from tracr.compiler import assemble\n",
    "from tracr.transformer import model\n",
    "from tracr.transformer.model import CompiledTransformerModel\n",
    "from tracr.transformer.encoder import CategoricalEncoder\n",
    "from tracr.compiler.assemble import AssembledTransformerModel\n",
    "\n",
    "from decompile_tracr.dataset import lib\n",
    "from decompile_tracr.dataset import data_utils\n",
    "from decompile_tracr.dataset import dataloading\n",
    "from decompile_tracr.dataset import config\n",
    "from decompile_tracr.dataset import compile as comp\n",
    "from decompile_tracr.tokenizing import tokenizer\n",
    "from decompile_tracr.tokenizing import vocab\n",
    "from decompile_tracr.sampling import sampling\n",
    "from decompile_tracr.sampling import rasp_utils\n",
    "from decompile_tracr.sampling.map_primitives import FunctionWithRepr\n",
    "from decompile_tracr.training import autoencoder\n",
    "from decompile_tracr.training import transformer\n",
    "from decompile_tracr.training.transformer import Residuals\n",
    "from decompile_tracr.training.metrics import Accuracy, Embed, Unembed, Decode\n",
    "\n",
    "from metamodels_for_rasp.train import Updater, TrainState\n",
    "\n",
    "\n",
    "def _compile(program):\n",
    "    return compiling.compile_rasp_to_model(\n",
    "        program,\n",
    "        vocab=set(range(5)),\n",
    "        max_seq_len=5,\n",
    "    )\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "key = jax.random.key(0)\n",
    "\n",
    "PLOT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(1000):\n",
    "#     try:\n",
    "#         program_toks = tokenizer.tokenize(sampling.sample(\n",
    "#             rng, program_length=5, only_categorical=True))\n",
    "#         assembled_model = comp.compile_tokens_to_model(program_toks)\n",
    "#         d_model = assembled_model.params['token_embed']['embeddings'].shape[-1]\n",
    "#         ds.append(d_model)\n",
    "#     except:\n",
    "#         continue\n",
    "# ds = np.array(ds)\n",
    "# \n",
    "# plt.hist(ds)\n",
    "# \n",
    "# d_model = 25\n",
    "# print(np.mean(ds), np.std(ds))\n",
    "# print(\"Frac too small: \", np.mean(ds < d_model))\n",
    "# print(\"Frac too large: \", np.mean(ds > 1.5*d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "program_toks = tokenizer.tokenize(sampling.sample(\n",
    "    rng, program_length=5, only_categorical=True))\n",
    "assembled_model = comp.compile_tokens_to_model(program_toks)\n",
    "d_model = assembled_model.params['token_embed']['embeddings'].shape[-1]\n",
    "print(d_model)\n",
    "\n",
    "residuals_sampler = autoencoder.ResidualsSampler(\n",
    "    model=assembled_model,\n",
    "    seq_len=6,\n",
    "    batch_size=2**12,\n",
    "    flatten_leading_axes=False,\n",
    ")\n",
    "\n",
    "embed = Embed(assembled_model=assembled_model)\n",
    "unembed = Unembed(assembled_model=assembled_model)\n",
    "accuracy = Accuracy(assembled_model=assembled_model)\n",
    "decode = Decode(assembled_model=assembled_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "key, subkey = jax.random.split(key)\n",
    "ae_state, ae_log, ae_model = autoencoder.train_autoencoder(\n",
    "    subkey, assembled_model, nsteps=50_000, lr=1e-3, hidden_size=50)\n",
    "print(f'training autoencoder took {time.time() - t:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plt.plot([x['train/loss'] for x in ae_log])\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    print('final loss:', ae_log[-1]['train/loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# compare to original\n",
    "key, subkey = jax.random.split(key)\n",
    "test_data = residuals_sampler.sample_residuals(subkey)\n",
    "\n",
    "#x = np.array([assembled_model.input_encoder.bos_encoding] + inputs)\n",
    "#x = np.expand_dims(x, 0)\n",
    "#assembled_out = assembled_model.apply(['compiler_bos'] + inputs)\n",
    "\n",
    "original = np.squeeze(np.array(test_data.residuals))\n",
    "decoded = ae_model.apply({'params': ae_state.params}, original)\n",
    "decoded = np.round(decoded, 0) # round to nearest integer\n",
    "decoded = np.array(decoded, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_acc = accuracy(original[:, -1], decoded[:, -1])\n",
    "print(ae_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ae_model.hidden_size)\n",
    "print(ae_model.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_range(*arrays):\n",
    "    all = np.concatenate(arrays)\n",
    "    return all.min(), all.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    x, y = original[0], decoded[0]  # take first example\n",
    "    _min, _max = get_range(x, y)\n",
    "\n",
    "    fig, axs = plt.subplots(len(x), 2, figsize=[10, 10])\n",
    "\n",
    "    axs[0, 0].set_title('Original')\n",
    "    for i, res in enumerate(x):\n",
    "        im = axs[i, 0].imshow(res, vmin=_min, vmax=_max)\n",
    "        axs[i, 0].set_ylabel(f'Layer {i}')\n",
    "\n",
    "    axs[0, 1].set_title('Decoded')\n",
    "    for i, res in enumerate(y):\n",
    "        im = axs[i, 1].imshow(res, vmin=_min, vmax=_max)\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_xticks(np.arange(x.shape[-1], step=2))\n",
    "        ax.set_xticklabels(np.arange(x.shape[-1], step=2))\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plt.imshow(x[-1] - y[-1])\n",
    "    plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_acc = accuracy(original[0, -1], decoded[0, -1])\n",
    "print(ae_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = assembled_model.apply(\n",
    "    [\"compiler_bos\"] + rng.integers(0, 5, size=(5,)).tolist())\n",
    "print(out.decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(unembed(original[:, -1]) == 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original[0, -1] - decoded[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = original[0, -1]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembed(np.round(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembed(x + rng.normal(size=x.shape) * 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembed(decoded[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    return ae_model.apply({'params': ae_state.params}, x, method=ae_model.encode)\n",
    "\n",
    "\n",
    "def decode(x):\n",
    "    return ae_model.apply({'params': ae_state.params}, x, method=ae_model.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encode(original[0, -1]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(enc)\n",
    "plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Per layer training (Ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch = transformer.DataGenerator(\n",
    "    assembled_model=assembled_model,\n",
    "    encode=encode,\n",
    "    batch_size=2**13,\n",
    "    seq_len=6,\n",
    ")\n",
    "\n",
    "model, state, log = transformer.train_transformer(\n",
    "    subkey, \n",
    "    get_batch=get_batch, \n",
    "    args=transformer.TransformerTrainingArgs(\n",
    "        nsteps=50_000,\n",
    "        learning_rate=1e-3,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    for k, v in log[0].items():\n",
    "        label = k[11:]\n",
    "        plt.plot([x[k] for x in log], label=label)\n",
    "        print(f'Final loss at {label}:', log[-1][k])\n",
    "    plt.yscale('log')\n",
    "    plt.xscale('log')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acts = model.apply({'params': state.params}, test_data.inputs)\n",
    "acts = dict(acts)\n",
    "acts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acts = dict(acts)\n",
    "tres = []\n",
    "for k in transformer.layer_names():\n",
    "    if k not in acts:\n",
    "        break\n",
    "    tres.append(acts[k])\n",
    "tres = einops.rearrange(tres, 'l b h w -> b l h w')\n",
    "tres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original = np.squeeze(x.residuals).astype(np.float32)\n",
    "decoded = decode(tres).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    x, y = original[0], decoded[0]  # take first example\n",
    "    _min, _max = get_range(x, y)\n",
    "\n",
    "    fig, axs = plt.subplots(len(x), 2, figsize=[10, 10])\n",
    "\n",
    "    axs[0, 0].set_title('Original')\n",
    "    for i, res in enumerate(x):\n",
    "        im = axs[i, 0].imshow(res, vmin=_min, vmax=_max)\n",
    "        axs[i, 0].set_ylabel(f'Layer {i}')\n",
    "\n",
    "    axs[0, 1].set_title('Decoded')\n",
    "    for i, res in enumerate(y):\n",
    "        im = axs[i, 1].imshow(res, vmin=_min, vmax=_max)\n",
    "\n",
    "    for ax in axs.flatten():\n",
    "        ax.set_xticks(np.arange(x.shape[-1], step=2))\n",
    "        ax.set_xticklabels(np.arange(x.shape[-1], step=2))\n",
    "\n",
    "    fig.colorbar(im, ax=axs, orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOT:\n",
    "    plt.imshow(x[-1] - y[-1])\n",
    "    plt.colorbar(orientation='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Autoencoder acc: ', ae_acc)\n",
    "print('Transformer acc: ', accuracy(original[:, -1], decoded[:, -1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
