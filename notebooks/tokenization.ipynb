{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import basis_inference\n",
    "from tracr.compiler import craft_graph_to_model\n",
    "from tracr.compiler import expr_to_craft_graph\n",
    "from tracr.compiler import rasp_to_graph\n",
    "from tracr.craft import bases\n",
    "from tracr.rasp import rasp\n",
    "import networkx as nx\n",
    "\n",
    "from rasp_generator import utils, sampling, map_primitives\n",
    "from tokenizer import compile_and_tokenize, vocab\n",
    "\n",
    "from rasp_generator.utils import FunctionWithRepr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = sampling.ProgramSampler()\n",
    "errs = sampler.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sop_1 = rasp.Map(lambda x: x + 1, rasp.indices)\n",
    "# sel_2 = rasp.Select(sop_1, rasp.tokens, rasp.Comparison.EQ)\n",
    "# sop_3 = rasp.Aggregate(sel_2, sop_1)\n",
    "# sop_4 = rasp.SequenceMap(lambda x, y: x + y, sop_1, sop_3)\n",
    "# sop_5 = rasp.SelectorWidth(sel_2)\n",
    "# sop_6 = rasp.SequenceMap(lambda x, y: x + y, sop_3, sop_5)\n",
    "\n",
    "sop_1 = rasp.Map(FunctionWithRepr(\"lambda x: x + 1\"), rasp.tokens)\n",
    "sel_2 = rasp.Select(sop_1, rasp.tokens, rasp.Comparison.EQ)\n",
    "sop_3 = rasp.Aggregate(sel_2, sop_1)\n",
    "sop_4 = rasp.SequenceMap(\n",
    "    FunctionWithRepr(\"lambda x, y: x * y\"), sop_1, sop_3)\n",
    "\n",
    "program = sop_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, graph, sources = compile_and_tokenize.compile_rasp_to_model_and_return_graph(\n",
    "    program,\n",
    "    vocab={0,1,2,3,4,5},\n",
    "    max_seq_len=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokens = compile_and_tokenize.compile_and_tokenize(program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [],\n",
       " 1: [8, 5, 0, 82, 94, 96],\n",
       " 2: [27, 3, 87, 8, 94, 96, 7, 5, 4, 27, 8, 96],\n",
       " 3: [9, 5, 1, 86, 8, 7, 96]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metamodels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
