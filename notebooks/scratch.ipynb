{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "from collections import defaultdict \n",
    "import jax\n",
    "import flax\n",
    "import chex\n",
    "from jaxtyping import ArrayLike\n",
    "from typing import Union, TypeVar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tracr.compiler.validating import validate\n",
    "from tracr.rasp.rasp import Map, SequenceMap, LinearSequenceMap, Select, Aggregate, Comparison, SelectorWidth, indices, tokens \n",
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import compiling\n",
    "from tracr.compiler.assemble import AssembledTransformerModel\n",
    "from tracr.compiler.craft_model_to_transformer import NoTokensError\n",
    "from tracr.compiler.basis_inference import InvalidValueSetError\n",
    "\n",
    "from rasp_tokenizer import tokenizer\n",
    "from rasp_tokenizer import vocab\n",
    "from rasp_tokenizer.compiling import COMPILER_BOS\n",
    "from rasp_generator.utils import sample_test_input\n",
    "from rasp_generator import sampling, utils, map_primitives\n",
    "from rasp_tokenizer.utils import RaspFlatDatapoint\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import os\n",
    "import pprint\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.typing import ArrayLike\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import chex\n",
    "from typing import Optional\n",
    "from dataclasses import asdict\n",
    "import numpy as np\n",
    "import wandb\n",
    "import argparse\n",
    "from etils import epath\n",
    "from tqdm import tqdm\n",
    "import orbax.checkpoint\n",
    "from etils import epath\n",
    "\n",
    "from nn_utils import schedules\n",
    "from meta_transformer import preprocessing, module_path, on_cluster, output_dir, interactive\n",
    "from meta_transformer.meta_model import DecompilerModel, mup_adamw\n",
    "from meta_transformer.train import Updater, Logger\n",
    "from meta_transformer.logger_config import setup_logger\n",
    "from meta_transformer.data import data_iterator\n",
    "import meta_transformer.utils\n",
    "\n",
    "from rasp_tokenizer import paths\n",
    "from rasp_tokenizer import vocab\n",
    "from rasp_tokenizer.utils import RaspFlatDatapoint\n",
    "logger = setup_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    datapath = paths.data_dir / \"5000programs.pkl\"\n",
    "    logger.info(f\"Loading train/val data from {datapath}.\")\n",
    "    with open(datapath, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def pad_to(x: np.ndarray, max_len: int, pad_value: int = 0):\n",
    "    \"\"\"Pad a 1D array to a given length. Not jittable.\"\"\"\n",
    "    x = np.array(x)\n",
    "    assert len(x) <= max_len\n",
    "    chex.assert_rank(x, 1)\n",
    "    return np.pad(x, (0, max_len - len(x)), constant_values=pad_value)\n",
    "\n",
    "\n",
    "def process_single_datapoint(\n",
    "        x: RaspFlatDatapoint,\n",
    "        d_model: int,\n",
    "        max_program_len: int = 32,\n",
    "        max_weights_len: int = 8192,\n",
    "    ):\n",
    "    \"\"\"Process a single datapoint for model input.\n",
    "    1) Program tokens: pad to max program length.\n",
    "    2) Weights: pad to max_weights_len, then chunk.\n",
    "    \"\"\"\n",
    "    if len(x.program) > max_program_len:\n",
    "        raise ValueError(f\"Program length ({len(x.program)}) exceeds \"\n",
    "                         f\"max program length ({max_program_len}).\")\n",
    "    elif len(x.weights) > max_weights_len:\n",
    "        raise ValueError(f\"Weights length ({len(x.weights)}) exceeds \"\n",
    "                         f\"max weights length ({max_weights_len}).\")\n",
    "    \n",
    "    program_toks = pad_to(x.program, max_program_len, pad_value=vocab.pad_id)\n",
    "    weights = pad_to(x.weights, max_weights_len)\n",
    "    weights = preprocessing.pad_and_chunk(weights, d_model)  # (n_chunks, d_model)\n",
    "    return {\n",
    "        \"program\": program_toks,\n",
    "        \"weights\": weights,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_data(\n",
    "        data: set[RaspFlatDatapoint],\n",
    "        d_model: int,\n",
    "        max_program_len: int = 32,\n",
    "        max_weights_len: int = 8192,\n",
    "    ):\n",
    "    n = len(data)\n",
    "    out = dict(program=[], weights=[])\n",
    "    for x in data:\n",
    "        x_proc = process_single_datapoint(\n",
    "            x, d_model, max_program_len, max_weights_len)\n",
    "        out[\"program\"].append(x_proc[\"program\"])\n",
    "        out[\"weights\"].append(x_proc[\"weights\"])\n",
    "    out = {k: np.stack(v) for k, v in out.items()}\n",
    "    chex.assert_shape(out[\"program\"], (n, max_program_len))\n",
    "    chex.assert_shape(out[\"weights\"], (n, max_weights_len//d_model, d_model))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-26 14:40:37 [INFO]: Loading train/val data from /home/lauro/projects/meta-models/rasp-generator/scripts/data/5000programs.pkl.\n"
     ]
    }
   ],
   "source": [
    "data = load_data()\n",
    "data = process_data(\n",
    "    data=data, \n",
    "    d_model=128,\n",
    ")\n",
    "#\n",
    "## normalize weights\n",
    "w_mean, w_std = data[\"weights\"].mean(), data[\"weights\"].std()\n",
    "data['weights'] = (data['weights'] - w_mean) / w_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10589, 64, 128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['weights'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data['weights']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isinf(data['weights']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(data['program']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isinf(data['program']).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
