{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "import sys\n",
    "from collections import defaultdict \n",
    "import jax\n",
    "import flax\n",
    "import chex\n",
    "from jaxtyping import ArrayLike\n",
    "from typing import Union, TypeVar\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import traceback\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from tracr.compiler.validating import validate\n",
    "from tracr.rasp.rasp import Map, SequenceMap, LinearSequenceMap, Select, Aggregate, Comparison, SelectorWidth, indices, tokens \n",
    "from tracr.rasp import rasp\n",
    "from tracr.compiler import compiling\n",
    "from tracr.compiler.assemble import AssembledTransformerModel\n",
    "from tracr.compiler.craft_model_to_transformer import NoTokensError\n",
    "from tracr.compiler.basis_inference import InvalidValueSetError\n",
    "from tracr.compiler import rasp_to_graph\n",
    "\n",
    "\n",
    "from decompile_tracr.dataset import lib\n",
    "from decompile_tracr.dataset import data_utils\n",
    "from decompile_tracr.dataset import config\n",
    "from decompile_tracr.dataset import compile as comp\n",
    "from decompile_tracr.tokenizing import tokenizer\n",
    "from decompile_tracr.tokenizing import vocab\n",
    "from decompile_tracr.sampling import sampling\n",
    "from decompile_tracr.sampling import rasp_utils\n",
    "\n",
    "\n",
    "rng = np.random.default_rng(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GPT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.virtualenvs/metamodels/lib/python3.10/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:160\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GPT'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/lauro/downloads/all_systems.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m openai_data \u001b[38;5;241m=\u001b[39m data[data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOrganization\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[43mopenai_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGPT\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/metamodels/lib/python3.10/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.virtualenvs/metamodels/lib/python3.10/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.virtualenvs/metamodels/lib/python3.10/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GPT'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/lauro/downloads/all_systems.csv')\n",
    "openai_data = data[data['Organization'] == \"OpenAI\"]\n",
    "openai_data[\"System\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>System</th>\n",
       "      <th>Domain</th>\n",
       "      <th>Organization</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication date</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Link</th>\n",
       "      <th>Citations</th>\n",
       "      <th>Notability criteria</th>\n",
       "      <th>Notability criteria notes</th>\n",
       "      <th>...</th>\n",
       "      <th>Dataset accessibility</th>\n",
       "      <th>Code accessibility</th>\n",
       "      <th>Hardware utilization</th>\n",
       "      <th>Finetune compute (FLOP)</th>\n",
       "      <th>Finetune compute notes</th>\n",
       "      <th>Batch size</th>\n",
       "      <th>Compute cost notes</th>\n",
       "      <th>Training cloud compute vendor</th>\n",
       "      <th>Batch size notes</th>\n",
       "      <th>Training data center</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>iGPT-L</td>\n",
       "      <td>Image generation,Vision</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Mark Chen, Alec Radford, Rewon Child, Jeff Wu,...</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>Generative Pretraining from Pixels</td>\n",
       "      <td>https://openai.com/blog/image-gpt/</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>GPT</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>A Radford, K Narasimhan, T Salimans, I Sutskever</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>Improving Language Understanding by Generative...</td>\n",
       "      <td>https://openai.com/blog/language-unsupervised/</td>\n",
       "      <td>8064.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>OpenAI Five Rerun</td>\n",
       "      <td>Games</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Christopher Berner, Greg Brockman, Brooke Chan...</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>Dota 2 with Large Scale Deep Reinforcement Lea...</td>\n",
       "      <td>https://cdn.openai.com/dota-2.pdf</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>\"On April 13th, 2019, OpenAI Five became the f...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>Hide and Seek</td>\n",
       "      <td>Games</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>B Baker, I Kanitscheider, T Markov, Y Wu</td>\n",
       "      <td>2019-09-17</td>\n",
       "      <td>Emergent Tool Use From Multi-Agent Autocurricula</td>\n",
       "      <td>https://openai.com/blog/emergent-tool-use/</td>\n",
       "      <td>538.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>GLIDE</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Alex Nichol, Prafulla Dhariwal, Aditya Ramesh,...</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>GLIDE: Towards Photorealistic Image Generation...</td>\n",
       "      <td>https://arxiv.org/abs/2112.10741</td>\n",
       "      <td>1931.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>ADM</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Prafulla Dhariwal, Alex Nichol</td>\n",
       "      <td>2021-05-11</td>\n",
       "      <td>Diffusion Models Beat GANs on Image Synthesis</td>\n",
       "      <td>https://arxiv.org/abs/2105.05233</td>\n",
       "      <td>3542.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>\"We show that diffusion models can achieve ima...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>GPT2-Large+LHOPT</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Diogo Almeida, Clemens Winter, Jie Tang, Wojci...</td>\n",
       "      <td>2021-06-02</td>\n",
       "      <td>A Generalizable Approach to Learning Optimizers</td>\n",
       "      <td>https://arxiv.org/abs/2106.00958</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Whisper</td>\n",
       "      <td>Speech</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Alec Radford, Jong Wook Kim, Tao Xu, Greg Broc...</td>\n",
       "      <td>2022-09-21</td>\n",
       "      <td>Robust Speech Recognition via Large-Scale Weak...</td>\n",
       "      <td>https://cdn.openai.com/papers/whisper.pdf</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Open source</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Statement Curriculum Learning</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Stanislas Polu, Jesse Michael Han, Kunhao Zhen...</td>\n",
       "      <td>2022-03-02</td>\n",
       "      <td>Formal Mathematics Statement Curriculum Learning</td>\n",
       "      <td>https://arxiv.org/abs/2202.01344</td>\n",
       "      <td>59.0</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>\"by applying this expert iteration to a manual...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>DALL-E</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Sc...</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>Zero-Shot Text-to-Image Generation</td>\n",
       "      <td>https://openai.com/blog/dall-e/</td>\n",
       "      <td>2969.0</td>\n",
       "      <td>Significant use,Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>OpenAI Five</td>\n",
       "      <td>Games</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Christopher Berner, Greg Brockman, Brooke Chan...</td>\n",
       "      <td>2019-12-13</td>\n",
       "      <td>Dota 2 with Large Scale Deep Reinforcement Lea...</td>\n",
       "      <td>https://arxiv.org/abs/1912.06680</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>\"On April 13th, 2019, OpenAI Five became the f...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cannot multiply the hardware quantity by train...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Whisper v2</td>\n",
       "      <td>Speech</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-05</td>\n",
       "      <td>openai/whisper-large-v2</td>\n",
       "      <td>https://huggingface.co/openai/whisper-large-v2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>GPT-3 175B (davinci)</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Tom B. Brown, Benjamin Mann, Nick Ryder, Melan...</td>\n",
       "      <td>2020-05-28</td>\n",
       "      <td>Language models are Few-Shot Learners</td>\n",
       "      <td>https://arxiv.org/abs/2005.14165</td>\n",
       "      <td>23023.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3200000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2M, per table 2.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>GPT-2 (1.5B)</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>A Radford, J Wu, R Child, D Luan, D Amodei</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>Language Models are Unsupervised Multitask Lea...</td>\n",
       "      <td>https://openai.com/blog/better-language-models/</td>\n",
       "      <td>15225.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://en.wikipedia.org/wiki/GPT-2#:~:text=Th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>Sora</td>\n",
       "      <td>Video</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-15</td>\n",
       "      <td>Video generation models as world simulators</td>\n",
       "      <td>https://openai.com/research/video-generation-m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>GPT-2 (345M)</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-14</td>\n",
       "      <td>Language Models are Unsupervised Multitask Lea...</td>\n",
       "      <td>https://openai.com/blog/better-language-models/</td>\n",
       "      <td>15225.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Whisper v3</td>\n",
       "      <td>Speech</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://huggingface.co/openai/whisper-large-v3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>seems not SOTA: \"Our studies show that... accu...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>DALL·E 3</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>James Betker, Gabriel Goh, Li Jing, Tim Brooks...</td>\n",
       "      <td>2023-10-19</td>\n",
       "      <td>Improving Image Generation with Better Captions</td>\n",
       "      <td>https://cdn.openai.com/papers/dall-e-3.pdf</td>\n",
       "      <td>183.0</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>GPT-4 Technical Report</td>\n",
       "      <td>https://arxiv.org/abs/2303.08774</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>See the paper, p.1: \"On a suite of traditional...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>706</th>\n",
       "      <td>DALL·E 2</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Aditya Ramesh, Prafulla Dhariwal, Alex Nichol,...</td>\n",
       "      <td>2022-04-06</td>\n",
       "      <td>Hierarchical Text-Conditional Image Generation...</td>\n",
       "      <td>https://cdn.openai.com/papers/dall-e-2.pdf</td>\n",
       "      <td>3802.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>Codex</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Mark Chen , Jerry Tworek, Heewoo Jun, Qiming Y...</td>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>Evaluating Large Language Models Trained on Code</td>\n",
       "      <td>https://openai.com/blog/openai-codex/</td>\n",
       "      <td>2387.0</td>\n",
       "      <td>Significant use,Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>Rubik's cube ADR robot</td>\n",
       "      <td>Robotics</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Ilge Akkaya, Marcin Andrychowicz, Maciek Choci...</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>Solving Rubik’s Cube with a Robot Hand</td>\n",
       "      <td>https://arxiv.org/abs/1910.07113</td>\n",
       "      <td>975.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>GPT-4V</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-09-25</td>\n",
       "      <td>GPT-4V(ision) system card</td>\n",
       "      <td>https://cdn.openai.com/papers/GPTV_System_Card...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Significant use</td>\n",
       "      <td>Incorporated into ChatGPT</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>ChatGPT (gpt-3.5-turbo)</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historical significance,Significant use</td>\n",
       "      <td>https://www.reuters.com/technology/chatgpt-set...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>Consistency Decoder</td>\n",
       "      <td>Image generation</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://github.com/openai/consistencydecoder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>Unreleased</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This model is derived from the denoising model...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>InstructGPT</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Long Ouyang, Pamela Mishkin, Jeff Wu, Xu Jiang...</td>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>Training language models to follow instruction...</td>\n",
       "      <td>https://cdn.openai.com/papers/Training_languag...</td>\n",
       "      <td>5461.0</td>\n",
       "      <td>Historical significance,Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>CLIP (ViT L/14@336px)</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Alec Radford, Jong Wook Kim, Chris Hallacy, Ad...</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>Learning Transferable Visual Models From Natur...</td>\n",
       "      <td>https://arxiv.org/abs/2103.00020</td>\n",
       "      <td>12732.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.kdnuggets.com/2021/03/beginners-gu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>GPT-4 Turbo</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-06</td>\n",
       "      <td>New models and developer products announced at...</td>\n",
       "      <td>https://openai.com/blog/new-models-and-develop...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SOTA improvement</td>\n",
       "      <td>\"More capable\" than GPT-4 according to OpenAI,...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>GPT-3.5 (text-davinci-003)</td>\n",
       "      <td>Language</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://platform.openai.com/docs/models/gpt-3-5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Historical significance,Significant use,SOTA i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>GAN-Advancer</td>\n",
       "      <td>Vision</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Tim Salimans, Ian Goodfellow, Wojciech Zaremba...</td>\n",
       "      <td>2016-12-05</td>\n",
       "      <td>Improved Techniques for Training GANs</td>\n",
       "      <td>https://dl.acm.org/doi/10.5555/3157096.3157346</td>\n",
       "      <td>7645.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1327</th>\n",
       "      <td>CLIP (ResNet-50)</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Alec Radford, Jong Wook Kim, Chris Hallacy, Ad...</td>\n",
       "      <td>2021-01-05</td>\n",
       "      <td>Learning Transferable Visual Models From Natur...</td>\n",
       "      <td>https://arxiv.org/abs/2103.00020</td>\n",
       "      <td>12732.0</td>\n",
       "      <td>Highly cited,SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1384</th>\n",
       "      <td>OpenAI TI7 DOTA 1v1</td>\n",
       "      <td>Games</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>Dota 2</td>\n",
       "      <td>https://openai.com/research/dota-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Historical significance,SOTA improvement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1389</th>\n",
       "      <td>iGPT-XL</td>\n",
       "      <td>Vision,Image generation</td>\n",
       "      <td>OpenAI</td>\n",
       "      <td>Mark Chen, Alec Radford, Rewon Child, Jeff Wu,...</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>Generative Pretraining from Pixels</td>\n",
       "      <td>https://openai.com/research/image-gpt</td>\n",
       "      <td>1190.0</td>\n",
       "      <td>Highly cited</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             System                   Domain Organization  \\\n",
       "8                            iGPT-L  Image generation,Vision       OpenAI   \n",
       "19                              GPT                 Language       OpenAI   \n",
       "72                OpenAI Five Rerun                    Games       OpenAI   \n",
       "155                   Hide and Seek                    Games       OpenAI   \n",
       "163                           GLIDE         Image generation       OpenAI   \n",
       "218                             ADM         Image generation       OpenAI   \n",
       "285                GPT2-Large+LHOPT                 Language       OpenAI   \n",
       "296                         Whisper                   Speech       OpenAI   \n",
       "322   Statement Curriculum Learning                 Language       OpenAI   \n",
       "421                          DALL-E         Image generation       OpenAI   \n",
       "428                     OpenAI Five                    Games       OpenAI   \n",
       "456                      Whisper v2                   Speech       OpenAI   \n",
       "508            GPT-3 175B (davinci)                 Language       OpenAI   \n",
       "522                    GPT-2 (1.5B)                 Language       OpenAI   \n",
       "532                            Sora                    Video       OpenAI   \n",
       "546                    GPT-2 (345M)                 Language       OpenAI   \n",
       "547                      Whisper v3                   Speech       OpenAI   \n",
       "678                        DALL·E 3         Image generation       OpenAI   \n",
       "683                           GPT-4               Multimodal       OpenAI   \n",
       "706                        DALL·E 2         Image generation       OpenAI   \n",
       "842                           Codex                 Language       OpenAI   \n",
       "862          Rubik's cube ADR robot                 Robotics       OpenAI   \n",
       "875                          GPT-4V               Multimodal       OpenAI   \n",
       "1055        ChatGPT (gpt-3.5-turbo)                 Language       OpenAI   \n",
       "1072            Consistency Decoder         Image generation       OpenAI   \n",
       "1248                    InstructGPT                 Language       OpenAI   \n",
       "1251          CLIP (ViT L/14@336px)               Multimodal       OpenAI   \n",
       "1282                    GPT-4 Turbo               Multimodal       OpenAI   \n",
       "1288     GPT-3.5 (text-davinci-003)                 Language       OpenAI   \n",
       "1297                   GAN-Advancer                   Vision       OpenAI   \n",
       "1327               CLIP (ResNet-50)               Multimodal       OpenAI   \n",
       "1384            OpenAI TI7 DOTA 1v1                    Games       OpenAI   \n",
       "1389                        iGPT-XL  Vision,Image generation       OpenAI   \n",
       "\n",
       "                                                Authors Publication date  \\\n",
       "8     Mark Chen, Alec Radford, Rewon Child, Jeff Wu,...       2020-06-17   \n",
       "19     A Radford, K Narasimhan, T Salimans, I Sutskever       2018-06-01   \n",
       "72    Christopher Berner, Greg Brockman, Brooke Chan...       2019-12-13   \n",
       "155            B Baker, I Kanitscheider, T Markov, Y Wu       2019-09-17   \n",
       "163   Alex Nichol, Prafulla Dhariwal, Aditya Ramesh,...       2021-12-20   \n",
       "218                      Prafulla Dhariwal, Alex Nichol       2021-05-11   \n",
       "285   Diogo Almeida, Clemens Winter, Jie Tang, Wojci...       2021-06-02   \n",
       "296   Alec Radford, Jong Wook Kim, Tao Xu, Greg Broc...       2022-09-21   \n",
       "322   Stanislas Polu, Jesse Michael Han, Kunhao Zhen...       2022-03-02   \n",
       "421   Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Sc...       2021-01-05   \n",
       "428   Christopher Berner, Greg Brockman, Brooke Chan...       2019-12-13   \n",
       "456                                                 NaN       2022-12-05   \n",
       "508   Tom B. Brown, Benjamin Mann, Nick Ryder, Melan...       2020-05-28   \n",
       "522          A Radford, J Wu, R Child, D Luan, D Amodei       2019-02-14   \n",
       "532                                                 NaN       2024-02-15   \n",
       "546                                                 NaN       2019-02-14   \n",
       "547                                                 NaN       2023-11-06   \n",
       "678   James Betker, Gabriel Goh, Li Jing, Tim Brooks...       2023-10-19   \n",
       "683                                              OpenAI       2023-03-15   \n",
       "706   Aditya Ramesh, Prafulla Dhariwal, Alex Nichol,...       2022-04-06   \n",
       "842   Mark Chen , Jerry Tworek, Heewoo Jun, Qiming Y...       2021-07-07   \n",
       "862   Ilge Akkaya, Marcin Andrychowicz, Maciek Choci...       2019-10-15   \n",
       "875                                                 NaN       2023-09-25   \n",
       "1055                                                NaN       2022-11-30   \n",
       "1072                                                NaN       2023-11-06   \n",
       "1248  Long Ouyang, Pamela Mishkin, Jeff Wu, Xu Jiang...       2022-01-27   \n",
       "1251  Alec Radford, Jong Wook Kim, Chris Hallacy, Ad...       2021-01-05   \n",
       "1282                                                NaN       2023-11-06   \n",
       "1288                                                NaN       2022-11-28   \n",
       "1297  Tim Salimans, Ian Goodfellow, Wojciech Zaremba...       2016-12-05   \n",
       "1327  Alec Radford, Jong Wook Kim, Chris Hallacy, Ad...       2021-01-05   \n",
       "1384                                                NaN       2017-08-11   \n",
       "1389  Mark Chen, Alec Radford, Rewon Child, Jeff Wu,...       2020-06-17   \n",
       "\n",
       "                                              Reference  \\\n",
       "8                    Generative Pretraining from Pixels   \n",
       "19    Improving Language Understanding by Generative...   \n",
       "72    Dota 2 with Large Scale Deep Reinforcement Lea...   \n",
       "155    Emergent Tool Use From Multi-Agent Autocurricula   \n",
       "163   GLIDE: Towards Photorealistic Image Generation...   \n",
       "218       Diffusion Models Beat GANs on Image Synthesis   \n",
       "285     A Generalizable Approach to Learning Optimizers   \n",
       "296   Robust Speech Recognition via Large-Scale Weak...   \n",
       "322    Formal Mathematics Statement Curriculum Learning   \n",
       "421                  Zero-Shot Text-to-Image Generation   \n",
       "428   Dota 2 with Large Scale Deep Reinforcement Lea...   \n",
       "456                             openai/whisper-large-v2   \n",
       "508               Language models are Few-Shot Learners   \n",
       "522   Language Models are Unsupervised Multitask Lea...   \n",
       "532         Video generation models as world simulators   \n",
       "546   Language Models are Unsupervised Multitask Lea...   \n",
       "547                                                 NaN   \n",
       "678     Improving Image Generation with Better Captions   \n",
       "683                              GPT-4 Technical Report   \n",
       "706   Hierarchical Text-Conditional Image Generation...   \n",
       "842    Evaluating Large Language Models Trained on Code   \n",
       "862              Solving Rubik’s Cube with a Robot Hand   \n",
       "875                           GPT-4V(ision) system card   \n",
       "1055                                                NaN   \n",
       "1072                                                NaN   \n",
       "1248  Training language models to follow instruction...   \n",
       "1251  Learning Transferable Visual Models From Natur...   \n",
       "1282  New models and developer products announced at...   \n",
       "1288                                                NaN   \n",
       "1297              Improved Techniques for Training GANs   \n",
       "1327  Learning Transferable Visual Models From Natur...   \n",
       "1384                                             Dota 2   \n",
       "1389                 Generative Pretraining from Pixels   \n",
       "\n",
       "                                                   Link  Citations  \\\n",
       "8                    https://openai.com/blog/image-gpt/     1190.0   \n",
       "19       https://openai.com/blog/language-unsupervised/     8064.0   \n",
       "72                    https://cdn.openai.com/dota-2.pdf     1420.0   \n",
       "155          https://openai.com/blog/emergent-tool-use/      538.0   \n",
       "163                    https://arxiv.org/abs/2112.10741     1931.0   \n",
       "218                    https://arxiv.org/abs/2105.05233     3542.0   \n",
       "285                    https://arxiv.org/abs/2106.00958       21.0   \n",
       "296           https://cdn.openai.com/papers/whisper.pdf     1092.0   \n",
       "322                    https://arxiv.org/abs/2202.01344       59.0   \n",
       "421                     https://openai.com/blog/dall-e/     2969.0   \n",
       "428                    https://arxiv.org/abs/1912.06680     1420.0   \n",
       "456      https://huggingface.co/openai/whisper-large-v2        NaN   \n",
       "508                    https://arxiv.org/abs/2005.14165    23023.0   \n",
       "522     https://openai.com/blog/better-language-models/    15225.0   \n",
       "532   https://openai.com/research/video-generation-m...        NaN   \n",
       "546     https://openai.com/blog/better-language-models/    15225.0   \n",
       "547      https://huggingface.co/openai/whisper-large-v3        NaN   \n",
       "678          https://cdn.openai.com/papers/dall-e-3.pdf      183.0   \n",
       "683                    https://arxiv.org/abs/2303.08774     3280.0   \n",
       "706          https://cdn.openai.com/papers/dall-e-2.pdf     3802.0   \n",
       "842               https://openai.com/blog/openai-codex/     2387.0   \n",
       "862                    https://arxiv.org/abs/1910.07113      975.0   \n",
       "875   https://cdn.openai.com/papers/GPTV_System_Card...        0.0   \n",
       "1055                                                NaN        NaN   \n",
       "1072       https://github.com/openai/consistencydecoder        NaN   \n",
       "1248  https://cdn.openai.com/papers/Training_languag...     5461.0   \n",
       "1251                   https://arxiv.org/abs/2103.00020    12732.0   \n",
       "1282  https://openai.com/blog/new-models-and-develop...        NaN   \n",
       "1288    https://platform.openai.com/docs/models/gpt-3-5        NaN   \n",
       "1297     https://dl.acm.org/doi/10.5555/3157096.3157346     7645.0   \n",
       "1327                   https://arxiv.org/abs/2103.00020    12732.0   \n",
       "1384                 https://openai.com/research/dota-2        0.0   \n",
       "1389              https://openai.com/research/image-gpt     1190.0   \n",
       "\n",
       "                                    Notability criteria  \\\n",
       "8                                          Highly cited   \n",
       "19                                         Highly cited   \n",
       "72                        Highly cited,SOTA improvement   \n",
       "155                                                 NaN   \n",
       "163                                        Highly cited   \n",
       "218                       Highly cited,SOTA improvement   \n",
       "285                                                 NaN   \n",
       "296                                    SOTA improvement   \n",
       "322                                    SOTA improvement   \n",
       "421                        Significant use,Highly cited   \n",
       "428                       Highly cited,SOTA improvement   \n",
       "456                                                 NaN   \n",
       "508                                        Highly cited   \n",
       "522                                        Highly cited   \n",
       "532                                    SOTA improvement   \n",
       "546                                        Highly cited   \n",
       "547                                                 NaN   \n",
       "678                                    SOTA improvement   \n",
       "683                       Highly cited,SOTA improvement   \n",
       "706                       Highly cited,SOTA improvement   \n",
       "842                        Significant use,Highly cited   \n",
       "862                                                 NaN   \n",
       "875                                     Significant use   \n",
       "1055            Historical significance,Significant use   \n",
       "1072                                                NaN   \n",
       "1248               Historical significance,Highly cited   \n",
       "1251                      Highly cited,SOTA improvement   \n",
       "1282                                   SOTA improvement   \n",
       "1288  Historical significance,Significant use,SOTA i...   \n",
       "1297                                       Highly cited   \n",
       "1327                      Highly cited,SOTA improvement   \n",
       "1384           Historical significance,SOTA improvement   \n",
       "1389                                       Highly cited   \n",
       "\n",
       "                              Notability criteria notes  ...  \\\n",
       "8                                                   NaN  ...   \n",
       "19                                                  NaN  ...   \n",
       "72    \"On April 13th, 2019, OpenAI Five became the f...  ...   \n",
       "155                                                 NaN  ...   \n",
       "163                                                 NaN  ...   \n",
       "218   \"We show that diffusion models can achieve ima...  ...   \n",
       "285                                                 NaN  ...   \n",
       "296                                                 NaN  ...   \n",
       "322   \"by applying this expert iteration to a manual...  ...   \n",
       "421                                                 NaN  ...   \n",
       "428   \"On April 13th, 2019, OpenAI Five became the f...  ...   \n",
       "456                                                 NaN  ...   \n",
       "508                                                 NaN  ...   \n",
       "522                                                 NaN  ...   \n",
       "532                                                 NaN  ...   \n",
       "546                                                 NaN  ...   \n",
       "547   seems not SOTA: \"Our studies show that... accu...  ...   \n",
       "678                                                 NaN  ...   \n",
       "683   See the paper, p.1: \"On a suite of traditional...  ...   \n",
       "706                                                 NaN  ...   \n",
       "842                                                 NaN  ...   \n",
       "862                                                 NaN  ...   \n",
       "875                           Incorporated into ChatGPT  ...   \n",
       "1055  https://www.reuters.com/technology/chatgpt-set...  ...   \n",
       "1072                                                NaN  ...   \n",
       "1248                                                NaN  ...   \n",
       "1251                                                NaN  ...   \n",
       "1282  \"More capable\" than GPT-4 according to OpenAI,...  ...   \n",
       "1288                                                NaN  ...   \n",
       "1297                                                NaN  ...   \n",
       "1327                                                NaN  ...   \n",
       "1384                                                NaN  ...   \n",
       "1389                                                NaN  ...   \n",
       "\n",
       "     Dataset accessibility Code accessibility Hardware utilization  \\\n",
       "8                      NaN                NaN                  NaN   \n",
       "19             Open source                NaN                  NaN   \n",
       "72                     NaN                NaN                  NaN   \n",
       "155                    NaN                NaN                  NaN   \n",
       "163                    NaN                NaN                  NaN   \n",
       "218                    NaN                NaN                  NaN   \n",
       "285                    NaN                NaN                  NaN   \n",
       "296                    NaN        Open source                  NaN   \n",
       "322                    NaN                NaN                  NaN   \n",
       "421                    NaN                NaN                  NaN   \n",
       "428                    NaN                NaN                  NaN   \n",
       "456                    NaN                NaN                  NaN   \n",
       "508                    NaN                NaN               0.2196   \n",
       "522                    NaN                NaN                  NaN   \n",
       "532                    NaN                NaN                  NaN   \n",
       "546                    NaN                NaN                  NaN   \n",
       "547                    NaN                NaN                  NaN   \n",
       "678                    NaN                NaN                  NaN   \n",
       "683                    NaN                NaN               0.3400   \n",
       "706                    NaN                NaN                  NaN   \n",
       "842                    NaN                NaN                  NaN   \n",
       "862                    NaN                NaN                  NaN   \n",
       "875                    NaN                NaN                  NaN   \n",
       "1055                   NaN                NaN                  NaN   \n",
       "1072            Unreleased         Unreleased                  NaN   \n",
       "1248                   NaN                NaN                  NaN   \n",
       "1251                   NaN                NaN                  NaN   \n",
       "1282                   NaN                NaN                  NaN   \n",
       "1288                   NaN                NaN                  NaN   \n",
       "1297                   NaN                NaN                  NaN   \n",
       "1327                   NaN                NaN                  NaN   \n",
       "1384                   NaN                NaN                  NaN   \n",
       "1389                   NaN                NaN                  NaN   \n",
       "\n",
       "     Finetune compute (FLOP)  \\\n",
       "8                        NaN   \n",
       "19                       NaN   \n",
       "72                       NaN   \n",
       "155                      NaN   \n",
       "163                      NaN   \n",
       "218                      NaN   \n",
       "285                      NaN   \n",
       "296                      NaN   \n",
       "322                      NaN   \n",
       "421                      NaN   \n",
       "428                      NaN   \n",
       "456                      NaN   \n",
       "508                      NaN   \n",
       "522                      NaN   \n",
       "532                      NaN   \n",
       "546                      NaN   \n",
       "547                      NaN   \n",
       "678                      NaN   \n",
       "683                      NaN   \n",
       "706                      NaN   \n",
       "842                      NaN   \n",
       "862                      NaN   \n",
       "875                      NaN   \n",
       "1055                     NaN   \n",
       "1072                     NaN   \n",
       "1248                     NaN   \n",
       "1251                     NaN   \n",
       "1282                     NaN   \n",
       "1288                     NaN   \n",
       "1297                     NaN   \n",
       "1327                     NaN   \n",
       "1384                     NaN   \n",
       "1389                     NaN   \n",
       "\n",
       "                                 Finetune compute notes Batch size  \\\n",
       "8                                                   NaN        NaN   \n",
       "19                                                  NaN        NaN   \n",
       "72                                                  NaN        NaN   \n",
       "155                                                 NaN        NaN   \n",
       "163                                                 NaN        NaN   \n",
       "218                                                 NaN        NaN   \n",
       "285                                                 NaN        NaN   \n",
       "296                                                 NaN        NaN   \n",
       "322                                                 NaN        NaN   \n",
       "421                                                 NaN        NaN   \n",
       "428                                                 NaN        NaN   \n",
       "456                                                 NaN        NaN   \n",
       "508                                                 NaN  3200000.0   \n",
       "522                                                 NaN        NaN   \n",
       "532                                                 NaN        NaN   \n",
       "546                                                 NaN        NaN   \n",
       "547                                                 NaN        NaN   \n",
       "678                                                 NaN        NaN   \n",
       "683                                                 NaN        NaN   \n",
       "706                                                 NaN        NaN   \n",
       "842                                                 NaN        NaN   \n",
       "862                                                 NaN        NaN   \n",
       "875                                                 NaN        NaN   \n",
       "1055                                                NaN        NaN   \n",
       "1072  This model is derived from the denoising model...        NaN   \n",
       "1248                                                NaN        NaN   \n",
       "1251                                                NaN        NaN   \n",
       "1282                                                NaN        NaN   \n",
       "1288                                                NaN        NaN   \n",
       "1297                                                NaN        NaN   \n",
       "1327                                                NaN        NaN   \n",
       "1384                                                NaN        NaN   \n",
       "1389                                                NaN        NaN   \n",
       "\n",
       "                                     Compute cost notes  \\\n",
       "8                                                   NaN   \n",
       "19                                                  NaN   \n",
       "72                                                  NaN   \n",
       "155                                                 NaN   \n",
       "163                                                 NaN   \n",
       "218                                                 NaN   \n",
       "285                                                 NaN   \n",
       "296                                                 NaN   \n",
       "322                                                 NaN   \n",
       "421                                                 NaN   \n",
       "428   Cannot multiply the hardware quantity by train...   \n",
       "456                                                 NaN   \n",
       "508                                                 NaN   \n",
       "522   https://en.wikipedia.org/wiki/GPT-2#:~:text=Th...   \n",
       "532                                                 NaN   \n",
       "546                                                 NaN   \n",
       "547                                                 NaN   \n",
       "678                                                 NaN   \n",
       "683                                                 NaN   \n",
       "706                                                 NaN   \n",
       "842                                                 NaN   \n",
       "862                                                 NaN   \n",
       "875                                                 NaN   \n",
       "1055                                                NaN   \n",
       "1072                                                NaN   \n",
       "1248                                                NaN   \n",
       "1251  https://www.kdnuggets.com/2021/03/beginners-gu...   \n",
       "1282                                                NaN   \n",
       "1288                                                NaN   \n",
       "1297                                                NaN   \n",
       "1327                                                NaN   \n",
       "1384                                                NaN   \n",
       "1389                                                NaN   \n",
       "\n",
       "      Training cloud compute vendor     Batch size notes Training data center  \n",
       "8                               NaN                  NaN                  NaN  \n",
       "19                              NaN                  NaN                  NaN  \n",
       "72                              NaN                  NaN                  NaN  \n",
       "155                             NaN                  NaN                  NaN  \n",
       "163                             NaN                  NaN                  NaN  \n",
       "218                             NaN                  NaN                  NaN  \n",
       "285                             NaN                  NaN                  NaN  \n",
       "296                             NaN                  NaN                  NaN  \n",
       "322                             NaN                  NaN                  NaN  \n",
       "421                             NaN                  NaN                  NaN  \n",
       "428                             NaN                  NaN                  NaN  \n",
       "456                             NaN                  NaN                  NaN  \n",
       "508                             NaN  3.2M, per table 2.1                  NaN  \n",
       "522                             NaN                  NaN                  NaN  \n",
       "532                             NaN                  NaN                  NaN  \n",
       "546                             NaN                  NaN                  NaN  \n",
       "547                             NaN                  NaN                  NaN  \n",
       "678                             NaN                  NaN                  NaN  \n",
       "683                             NaN                  NaN                  NaN  \n",
       "706                             NaN                  NaN                  NaN  \n",
       "842                             NaN                  NaN                  NaN  \n",
       "862                             NaN                  NaN                  NaN  \n",
       "875                             NaN                  NaN                  NaN  \n",
       "1055                            NaN                  NaN                  NaN  \n",
       "1072                            NaN                  NaN                  NaN  \n",
       "1248                            NaN                  NaN                  NaN  \n",
       "1251                            NaN                  NaN                  NaN  \n",
       "1282                            NaN                  NaN                  NaN  \n",
       "1288                            NaN                  NaN                  NaN  \n",
       "1297                            NaN                  NaN                  NaN  \n",
       "1327                            NaN                  NaN                  NaN  \n",
       "1384                            NaN                  NaN                  NaN  \n",
       "1389                            NaN                  NaN                  NaN  \n",
       "\n",
       "[33 rows x 56 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_data[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample, compile, and format for model input\n",
    "\n",
    "def to_datapoint(program: rasp.SOp):\n",
    "    tokens = tokenizer.tokenize(program)\n",
    "    weights = comp.get_weights(tokens, max_weights_len=config.MAX_WEIGHTS_LENGTH)\n",
    "\n",
    "    datapoint = {\n",
    "        \"tokens\": tokens,\n",
    "        \"weights\": weights,\n",
    "        \"program_id\": 1,\n",
    "    }\n",
    "\n",
    "    datapoint = {\n",
    "        \"weights\": np.concatenate(datapoint[\"weights\"]).astype(data_utils.NUMPY_DTYPE),\n",
    "        \"tokens\": np.concatenate(datapoint[\"tokens\"]).astype(data_utils.NUMPY_DTYPE),\n",
    "        \"program_id\": datapoint[\"program_id\"],\n",
    "    }\n",
    "\n",
    "    datapoint = data_utils.process_single_datapoint(\n",
    "        datapoint, \n",
    "        d_model=128,\n",
    "        max_weights_len=config.MAX_WEIGHTS_LENGTH*4,\n",
    "        max_rasp_len=config.MAX_RASP_LENGTH*4,\n",
    "    )\n",
    "\n",
    "    return datapoint\n",
    "\n",
    "\n",
    "def print_token_legend():\n",
    "    tokens_to_print = [\n",
    "        \"BOS\",\n",
    "        \"EOS\",\n",
    "        \"PAD\",\n",
    "        \"SelectAggregate\",\n",
    "        \"Map\",\n",
    "        \"SequenceMap\",\n",
    "    ]\n",
    "    print(\"Token Legend:\")\n",
    "    for token in tokens_to_print:\n",
    "        token_id = vocab.vocab.index(token)\n",
    "        print(f\"{token}: {token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = compiling.compile_rasp_to_model(rasp.Map(lambda x: x + 1, rasp.tokens), vocab=set(range(5)), max_seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['pos_embed', 'token_embed', 'transformer/layer_0/attn/key', 'transformer/layer_0/attn/linear', 'transformer/layer_0/attn/query', 'transformer/layer_0/attn/value', 'transformer/layer_0/mlp/linear_1', 'transformer/layer_0/mlp/linear_2'])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embed', 'layer_0/attn', 'layer_0/mlp', 'layer_1/attn', 'layer_1/mlp']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_utils.layer_names(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax.flatten_util.ravel_pytree([m.params['token_embed'], m.params['pos_embed']])[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['tokens', 'weights', 'program_id'])\n",
      "\n",
      "(128,)\n",
      "(256, 128)\n",
      "['-350.0', '-349.0', '-250.0', '-249.0', '-150.0', '-149.0', '-50.0', '-49.0', '-2.0', '-1.0', '0.0', '0.05', '1.0', '2.0', '3.0', '4.0', '5.0', '7.0', '9.0', '10.0', '13.0', '17.0', '50.0', '100.0']\n",
      "\n",
      "map_367 = Map(lambda x: x, indices)    # type: float\n",
      "sequence_map_368 = SequenceMap(lambda x, y: x * y, tokens, indices)    # type: categorical\n",
      "map_370 = Map(lambda x: x > 3.5, map_367)    # type: bool\n",
      "map_372 = Map(lambda x: int(x), map_367)    # type: categorical\n",
      "map_369 = Map(lambda x: x + 1, sequence_map_368)    # type: float\n",
      "select_396 = Select(map_372, tokens, predicate=Comparison.NEQ)\n",
      "linear_sequence_map_381 = LinearSequenceMap(map_369, map_367, -1, 2)    # type: float\n",
      "aggregate_395 = Aggregate(select_396, map_370)    # type: float\n",
      "linear_sequence_map_433 = LinearSequenceMap(aggregate_395, linear_sequence_map_381, -2, 1)    # type: float\n",
      "\n",
      "[ 6.  7.  6. 49. 48. 14. 31. 23. 17. 50. 22. 20. 24. 74. 23.  7.  6.  7.\n",
      "  6. 61. 48. 14. 47. 49. 17. 68. 48. 14. 36. 50. 17. 67. 22. 14. 29. 49.\n",
      "  7.  6. 70. 48. 18. 67. 74. 15. 61.  7.  6. 69. 48. 13. 68. 49.  0.  4.\n",
      "  7.  6.  7.  6. 71. 48. 13. 70. 69.  1.  3.  7. 16. 16. 16. 16. 16. 16.\n",
      " 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      " 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      " 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16. 16.\n",
      " 16. 16.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "program = sampling.sample(rng, program_length=10)\n",
    "datapoint = to_datapoint(program)\n",
    "\n",
    "\n",
    "print(datapoint.keys())\n",
    "print()\n",
    "print(datapoint['tokens'].shape)\n",
    "print(datapoint['weights'].shape)\n",
    "print([str(x) for x in np.unique(datapoint['weights'])])\n",
    "print()\n",
    "rasp_utils.print_program(program)\n",
    "print()\n",
    "print(datapoint['tokens'])\n",
    "print()\n",
    "\n",
    "#plt.imshow(datapoint['weights'], aspect='auto')\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x70f12f74b5b0>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(datapoint['weights'].flatten()[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0', '0.05', '1.0', '50.0', '100.0']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.unique(datapoint['weights']), 'o')\n",
    "plt.yscale('symlog')\n",
    "print([str(x) for x in np.unique(datapoint['weights'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SequenceMaps consist of {-1, 0, 1}s\n",
    "# SelectAggregates have 100s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Legend:\n",
      "BOS: 6\n",
      "EOS: 7\n",
      "PAD: 16\n",
      "SelectAggregate: 18\n",
      "Map: 14\n",
      "SequenceMap: 20\n"
     ]
    }
   ],
   "source": [
    "print_token_legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta-models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
